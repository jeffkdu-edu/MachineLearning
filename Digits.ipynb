{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsn6t+I7L5r5KpP94CLZR3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffkdu-edu/MachineLearning/blob/main/Digits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in the mnist digit dataset\n",
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import check_random_state\n",
        "import random\n",
        "from sklearn import tree\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "# works with as_frame set to False otherwise error on X[permutation]\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)"
      ],
      "metadata": {
        "id": "q5p_RmWC45C4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KB0MV4C1jCAC"
      },
      "source": [
        "Divide the data into a training set and test set, randomly selecting 5000 examples for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ2-XGCVTBK3"
      },
      "source": [
        "train_samples = 5000\n",
        "\n",
        "random_state = check_random_state(0)\n",
        "permutation = random_state.permutation(X.shape[0])\n",
        "X = X[permutation]\n",
        "y = y[permutation]\n",
        "X = X.reshape((X.shape[0], -1))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, train_size=train_samples, test_size=10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examine one of the instances. It says it is a '7' but it is not evident why exactly."
      ],
      "metadata": {
        "id": "2LblFTbWwR5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# i = random.randint(0, len(X_train))\n",
        "print(X_train[500])\n",
        "y_train[500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nFn7dx-3wFyK",
        "outputId": "f4461f97-352b-4c6a-91e1-cc8c953c5fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  20. 121. 128. 253.\n",
            " 255. 253. 253. 253. 116.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.  34. 107. 107. 200. 252. 252. 252.\n",
            " 253. 252. 252. 252. 249. 119.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0. 133. 235. 252. 252. 252. 252. 252. 252.\n",
            " 253. 252. 252. 252. 252. 198.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.  39. 207. 248. 252. 252. 252. 197. 172.  95.  39.\n",
            "  39.  39. 160. 252. 252. 198.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0. 121. 252. 252. 217. 199.  87.  17.   0.   0.   0.\n",
            "   0.   0. 226. 252. 252. 163.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.  32. 192.  79.  31.  14.   0.   0.   0.   0.   0.\n",
            "   0.  80. 245. 252. 238.  52.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0. 107. 252. 252. 185.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0. 191. 252. 252. 185.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   4.  14.  14.  99. 146. 146.\n",
            " 147. 247. 252. 252. 224. 146.  56.  14.   6.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.  43. 164. 252. 252. 252. 252. 252.\n",
            " 253. 252. 252. 252. 252. 252. 252. 252. 176.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.  45. 162. 253. 253. 253. 253. 253. 253.\n",
            " 255. 253. 253. 253. 253. 253. 253. 253. 253. 120.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.  54. 235. 252. 252. 252. 241. 145. 202.\n",
            " 253. 252. 252. 161. 145.  47. 104. 131.  13.   6.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.  22.  26.  26.  26.  23.   0.  63.\n",
            " 253. 252. 252.  39.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 133.\n",
            " 253. 252. 252.  39.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 133.\n",
            " 253. 252. 227.  29.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   3. 158.\n",
            " 253. 252. 158.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  14. 252.\n",
            " 253. 252. 158.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  12. 239.\n",
            " 253. 252.  75.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 127.\n",
            " 253. 190.  11.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            " 253. 145.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'7'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's print out the 500th \n",
        " item in the dataset and its label."
      ],
      "metadata": {
        "id": "4_SSfOHWxSpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = 500\n",
        "img = np.array(X_train[i]).reshape(28,28)\n",
        "plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
        "plt.show()\n",
        "y_train[i]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "ZnwzIfbswnX6",
        "outputId": "11744e27-4e81-49d2-b953-6d6fc7454a2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'7'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at a decision tree classifier.\n",
        "The result isn't very good at ~ 77%"
      ],
      "metadata": {
        "id": "c_6PoMDayAjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = tree.DecisionTreeClassifier(max_leaf_nodes=170)\n",
        "clf = clf.fit(X_train, y_train)\n",
        "correct= 0\n",
        "for i in range(len(X_test)):\n",
        "  if clf.predict([X_test[i]]) == y_test[i]:\n",
        "    correct += 1\n",
        "  acc = [100.0 * correct / len(X_test)]\n",
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2TXGniHyYFA",
        "outputId": "285ad67d-174b-4642-ee6c-3698b64831cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[76.53]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next let's try a linear neural network and see if we get better results.\n",
        "Here we can try a MLP(multi layer perceptron) classifier. Also the hidden_layer_sizes hyperparameter is set to an empty list '[]' because we are building a network with no hidden units. The activation is set to 'identity' because we are using linear activation with the accumulated sum identical. Even with no hidden units, he result is a solid 'B' with an ~86% . Still not great. Neuaral networks are suited for gathering low level info from the entire input. The decision tree only looked 170 of the pixels wheras the neural network uses all 784 pixels. Therefore, we get a better score than with the decision tree. "
      ],
      "metadata": {
        "id": "mGtKP6xsz9PE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MLPClassifier(hidden_layer_sizes=[], max_iter=10000, activation='identity')\n",
        "clf.fit(X_train, y_train)\n",
        "score = clf.score(X_test, y_test)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Xm8gjgUzLD_",
        "outputId": "12bb5755-7991-4d74-d6e9-bc6b61ab8e6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The network architecture has one input node fro each pixel in the image.\n",
        "784 input nodes(pixels) and 10 output nodes(for numbers 0 - 9)."
      ],
      "metadata": {
        "id": "Y0w85tkb47-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(clf.coefs_[0].T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geIWgE8G2OQK",
        "outputId": "d316141f-fbe5-4e5e-d4db-076063b97dd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will add one hidden layer and expand the number of hidden units from 10 to 200 in intervals of 10. We'll print the accuracy of each model given the number of hidden units."
      ],
      "metadata": {
        "id": "VucBbLM15oSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,21):\n",
        "  nhidden = i*10\n",
        "  clf = MLPClassifier(hidden_layer_sizes=[nhidden], max_iter = 10000)\n",
        "  clf.fit(X_train, y_train)\n",
        "  score = clf.score(X_test, y_test)\n",
        "  print(nhidden, score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMHidvuj5d6o",
        "outputId": "9d4f3c94-9c70-473f-b5f9-161e72099dad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 0.4207\n",
            "20 0.6937\n",
            "30 0.868\n",
            "40 0.8728\n",
            "50 0.8585\n",
            "60 0.8804\n",
            "70 0.8742\n",
            "80 0.8685\n",
            "90 0.8922\n",
            "100 0.8842\n",
            "110 0.8812\n",
            "120 0.8983\n",
            "130 0.9072\n",
            "140 0.9011\n",
            "150 0.9076\n",
            "160 0.9045\n",
            "170 0.9066\n",
            "180 0.9112\n",
            "190 0.9072\n",
            "200 0.9015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like the best number of hidden units is around 170 - 180. This gives us the best score of about 90 - 91 %. That's an A-. Getting better."
      ],
      "metadata": {
        "id": "N9UNn_y28lhi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets take the number of hidden units to be about 170 and train 10 times to see if we get a solid performance for all runs."
      ],
      "metadata": {
        "id": "B9OdEoY39zrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(11):\n",
        "  nhidden = 170\n",
        "  clf = MLPClassifier(hidden_layer_sizes=[nhidden], max_iter = 10000)\n",
        "  clf.fit(X_train, y_train)\n",
        "  score = clf.score(X_test, y_test)\n",
        "  print(nhidden, score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "404e3e21-7fe8-44a8-f11a-7dd92ae0a4ff",
        "id": "4LTBSOtT-D0O"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "170 0.9037\n",
            "170 0.8996\n",
            "170 0.9116\n",
            "170 0.9054\n",
            "170 0.9115\n",
            "170 0.9002\n",
            "170 0.9089\n",
            "170 0.915\n",
            "170 0.8978\n",
            "170 0.9032\n",
            "170 0.9013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The network is performing consistantly and above the network with no hidden units with a top score around 91% accuracy. Not bad! 🙂"
      ],
      "metadata": {
        "id": "5U97JevF_QfX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XmHpvu-G-Phs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}